# -*- coding: utf-8 -*-
"""BLACKcoffer script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jiJddFRCaAVJRWSJ3oRiW2QXCFy9rfqB
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from textblob import TextBlob
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import cmudict

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('cmudict')

with open('/content/drive/MyDrive/STOPWORDSSSS.txt', 'r') as file:
    custom_stopwords = [word.strip() for word in file]

def extract_article_text(url):
    try:
        response = requests.get(url)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        title = soup.title.text.strip()
        article_text = ' '.join([p.text for p in soup.find_all('p')])

        return title, article_text
    except Exception as e:
        print(f"Error extracting data from {url}: {e}")
        return None, None


pronouncing_dict = cmudict.dict()

def count_syllables(word):
    if word.lower() in pronouncing_dict:
        return max([len(list(y for y in x if y[-1].isdigit())) for x in pronouncing_dict[word.lower()]])
    else:
        return max(1, len(word) // 3)

def count_personal_pronouns(text):
    blob = TextBlob(text)
    personal_pronouns = sum(1 for word, pos in blob.tags if pos == 'PRP' or pos == 'PRP$')
    return personal_pronouns

def calculate_text_metrics(text, custom_stopwords):
    words = word_tokenize(text)
    sentences = sent_tokenize(text)
    avg_sentence_length = sum(len(word_tokenize(sentence)) for sentence in sentences) / len(sentences)


    words = [word for word in words if word.lower() not in custom_stopwords]

    complex_words = [word for word in words if len(word) > 6]
    complex_word_count = len(complex_words)
    percentage_complex_words = (len(complex_words) / len(words)) * 100 if len(words) > 0 else 0

    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)

    avg_words_per_sentence = len(words) / len(sentences) if len(sentences) > 0 else 0

    word_count = len(words)

    syllable_per_word = sum(count_syllables(word) for word in words) / len(words) if len(words) > 0 else 0

    personal_pronouns = count_personal_pronouns(text)

    avg_word_length = sum(len(word) for word in words) / len(words) if len(words) > 0 else 0



    blob = TextBlob(text)
    positive_score = blob.sentiment.polarity
    negative_score = -blob.sentiment.polarity
    polarity_score = blob.sentiment.polarity
    subjectivity_score = blob.sentiment.subjectivity


    return positive_score, negative_score, polarity_score, subjectivity_score, \
        avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, \
        complex_word_count, word_count, syllable_per_word, personal_pronouns, avg_word_length


excel_file_path = '/content/drive/MyDrive/Copy of Input.xlsx'
df = pd.read_excel(excel_file_path)

output_data = []

for index, row in df.iterrows():
    url_id = row['URL_ID']
    url = row['URL']

    title, article_text = extract_article_text(url)

    if title and article_text:
        positive_score, negative_score, polarity_score, subjectivity_score, \
        avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, \
        complex_word_count, word_count, syllable_per_word, personal_pronouns, avg_word_length = calculate_text_metrics(article_text, custom_stopwords)

        output_data.append({
            'URL_ID': url_id,
            'Title': title,
            'POSITIVE SCORE': positive_score,
            'NEGATIVE SCORE': negative_score,
            'POLARITY SCORE': polarity_score,
            'SUBJECTIVITY SCORE': subjectivity_score,
            'AVG SENTENCE LENGTH': avg_sentence_length,
            'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,
            'FOG INDEX': fog_index,
            'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,
            'COMPLEX WORD COUNT': complex_word_count,
            'WORD COUNT': word_count,
            'SYLLABLE PER WORD': syllable_per_word,
            'PERSONAL PRONOUNS': personal_pronouns,
            'AVG WORD LENGTH': avg_word_length
        })

# Create a DataFrame from the output data
output_df = pd.DataFrame(output_data)

# Save the output DataFrame to an Excel file
output_excel_path = '/content/drive/MyDrive/Output.xlsx'
output_df.to_excel(output_excel_path, index=False)